### | These functions are used to digitally manipulate the WS and simulate TMA core sampling, and display the resulting data. |###
#     Last Updated: June 1, 2023 by Michael Fotheringham  

import datetime
import os
import pandas as pd
import numpy as np
from shapely.geometry import Polygon as shapelyPolygon
from shapely.geometry import Point, MultiPolygon
from shapely.ops import unary_union
import geopandas as gpd
import matplotlib.pyplot as plt


def load_sim_data(block, parent_filepath):
    # Ensure proper formatting
    parent_filepath = os.path.join(parent_filepath, block).replace("\\", "/") 
    if not os.path.exists(os.path.join(parent_filepath, "Object_Data.csv").replace("\\", "/")):
        raise FileNotFoundError(os.path.join(parent_filepath, 'Object_Data.csv').replace("\\", "/") + " doesn't exist.")
    # Load object data
    object_data = pd.read_csv(os.path.join(parent_filepath, 'Object_Data.csv').replace("\\", "/"))
    object_data = object_data[['Analysis Region', 'Algorithm Name', 'Object Id', 'XMin', 'XMax', 'YMin', 'YMax', 'CD8']]
    object_data = object_data[(object_data["Analysis Region"] == "Partition Zone") & (object_data["CD8"] == 1)]
    cell_coords = []
    for idx, row in object_data.iterrows():
        cell_coord = ((row["XMin"] + row["XMax"]) / 2, (row["YMin"] + row["YMax"]) / 2)
        cell_coords.append(cell_coord)
    object_data["Cell Centre"] = cell_coords
    object_data = object_data.drop(['XMin', 'XMax', 'YMin', 'YMax'], axis=1)
    # Load annotation vertices (individual lines of file)
    if not os.path.exists(os.path.join(parent_filepath, 'Annotations.annotations').replace("\\", "/")):
        raise FileNotFoundError(os.path.join(parent_filepath, 'Annotations.annotations').replace("\\", "/") + " doesn't exist.")
    with open(os.path.join(parent_filepath, 'Annotations.annotations').replace("\\", "/"), "r") as f:
        lines = f.readlines()
    # Convert vertices to polygon
    positive_region = []
    layers = []
    polygons = []
    vertices = []
    layer_name = []
    region_status = []
    for line in lines:
        if "<Annotation Name=" in line:
            # Start a new polygon
            layer_name = line.split('Name="')[1].split('" Visible=')[0]
        elif "<Region Type=" in line:
            region_status = line.split('NegativeROA="')[1].split('">')[0] == '0'
            vertices = []
        elif "<V X=" in line:
            # Extract the x,y coords from the line
            x = int(line.split('X="')[1].split('" Y=')[0])
            y = int(line.split('Y="')[1].split('" />')[0])
            vertices.append((x, y))
        elif "</Region>" in line:
            # End current polygon and add it to the list
            if len(vertices) >= 4:
                polygons.append(shapelyPolygon(vertices))
                layers.append(layer_name)
                positive_region.append(region_status)
            else:
                print(f"Small annotation detected for {block}, excluding annotation with {len(vertices)} vertices: {vertices}.")
    # create polygon dataframe to keep track of individual layers on regions
    annotation_layers = pd.DataFrame({"Layer": layers, "Positive Region": positive_region, "Polygon": polygons, "Area": [shapelyPolygon(i).area for i in polygons]})
    annotation_layers = annotation_layers[annotation_layers["Layer"].isin(["Tumour", "Peritumoral Zone", "Partition Zone"])]
    annotation_layers = annotation_layers.sort_values(["Layer", "Positive Region", "Area"], ascending=[False, False, False])
    # Compile relevant annotation layers
    plot_annotations = annotation_layers[((annotation_layers["Layer"] == "Partition Zone") & (annotation_layers["Positive Region"] == 0)) | ((annotation_layers["Layer"] == "Tumour") & (annotation_layers["Positive Region"] == 1))]
    return object_data, plot_annotations


def n_core_sampler(block, object_data, plot_annotations, number_of_tumour_regions, circle_radius, boundary_type, n_cores, microns_per_pixel=0.22715):
    # if microns_per_pixel is None or not isinstance(microns_per_pixel, (int, float)):
    #     raise ValueError("microns_per_pixel is either missing or not a number. Should be 0.22715.")
    # if number_of_tumour_regions is None or not isinstance(number_of_tumour_regions, (int, float)):
    #     raise ValueError("number_of_tumour_layers is either missing or not a number.")
    # if circle_radius is None or not isinstance(circle_radius, (int, float)):
    #     raise ValueError("circle_radius is either missing or not a number.")
    # if boundary_type is None or not isinstance(boundary_type, str):
    #     raise ValueError("boundary_type is either missing or not a string. Must be 'Tumour' or 'IM'.")
    # if boundary_type not in ["Tumour", "IM"]:
    #     raise ValueError("boundary_type must be 'Tumour' or 'IM'.")
    # if n_cores is None or not isinstance(n_cores, int):
    #     raise ValueError("n_cores is either missing or not a number.")
    geometry = [Point(x, y) for x, y in object_data["Cell Centre"]]
    cell_data_gdf = gpd.GeoDataFrame(object_data, geometry=geometry)
    # Create a spatial index for faster intersection checks
    # cell_data_sindex = cell_data_gdf.sindex
    # Combine polygons, add to lists to make iterable for MultiPolygon
    tumour_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"].tolist()).buffer(0))
    outer_IM_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"][0:number_of_tumour_regions].tolist()).buffer(500 / microns_per_pixel))
    inner_IM_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"][0:number_of_tumour_regions].tolist()).buffer(-500 / microns_per_pixel))
    negative_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Partition Zone"]["Polygon"].tolist()).buffer(0))
    net_tumour = tumour_polygons.difference(negative_polygons)
    partition = outer_IM_polygons.difference(negative_polygons)
    net_IM = partition.difference(inner_IM_polygons)
    analysis_polygon = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"].tolist()).buffer(1000 / microns_per_pixel))
    analysis_polygon = analysis_polygon.difference(negative_polygons)
    # Randomly select core points
    radius = circle_radius * 1000 / microns_per_pixel
    diameter = radius * 2
    points = []
    cell_density = []
    cell_counts = []
    core_areas = []
    n_den_stdev = []
    n_den_sterr = []
    mm2_per_pixels2 = (microns_per_pixel / 1000) ** 2
    if boundary_type == "Tumour":
        if net_tumour.area > n_cores * np.pi * radius ** 2:
            min_x, min_y, max_x, max_y = net_tumour.bounds
            for i in range(n_cores):
                attempt_n = 0
                while attempt_n < 200:
                    x = np.random.uniform(min_x, max_x)
                    y = np.random.uniform(min_y, max_y)
                    centre = Point(x, y)
                    # Ensure that there are no overlapping cores
                    overlapping = False
                    for prev_point in points:
                        if prev_point.distance(centre) < diameter:
                            overlapping = True
                            attempt_n += 1
                            break
                    if not overlapping and net_tumour.contains(centre):
                        # Ensure core is at least 50% tumour
                        circle = centre.buffer(radius)
                        intersection = circle.intersection(net_tumour)
                        proportion = intersection.area / circle.area
                        if proportion >= 0.5:
                            points.append(centre)
                            # Find the cells that intersect with poly_hpf
                            intersecting_cells = cell_data_gdf[cell_data_gdf.intersects(circle.intersection(net_tumour))]
                            # Count the intersecting cells
                            cell_count = len(intersecting_cells)
                            cell_density.append(cell_count / (circle.intersection(analysis_polygon).area * mm2_per_pixels2))
                            cell_counts.append(cell_count)
                            core_areas.append(circle.intersection(analysis_polygon).area * mm2_per_pixels2)
                            break
                        else: attempt_n += 1
                    else:
                        attempt_n += 1
    if boundary_type == "IM":
        if net_IM.area > n_cores * np.pi * radius ** 2:
            min_x, min_y, max_x, max_y = net_IM.bounds
            for i in range(n_cores):
                attempt_n = 0
                while attempt_n < 200:
                    x = np.random.uniform(min_x, max_x)
                    y = np.random.uniform(min_y, max_y)
                    centre = Point(x, y)
                    # Ensure that there are no overlapping cores
                    overlapping = False
                    for prev_point in points:
                        if prev_point.distance(centre) < diameter:
                            overlapping = True
                            attempt_n += 1
                            break
                    if not overlapping and net_IM.contains(centre):
                        # Ensure 80% >= tumour >= 10%, and 10% >= stroma
                        circle = centre.buffer(radius)
                        intersection = circle.intersection(net_tumour)
                        proportion = intersection.area / circle.area
                        proportion_stroma = circle.intersection(partition.difference(net_tumour)).area / circle.area
                        if (proportion >= 0.10) & (proportion <= 0.80) & (proportion_stroma > 0.10):
                            points.append(centre)
                            # Find the cells that intersect with poly_hpf
                            intersecting_cells = cell_data_gdf[cell_data_gdf.intersects(circle.intersection(net_IM))]
                            # Count the intersecting cells
                            cell_count = len(intersecting_cells)
                            cell_density.append(cell_count / (circle.intersection(analysis_polygon).area * mm2_per_pixels2))
                            cell_counts.append(cell_count)
                            core_areas.append(circle.intersection(analysis_polygon).area * mm2_per_pixels2)
                            break
                        else: attempt_n += 1
                    else:
                        attempt_n += 1
    # Compute averages and stdev and sterror
    cores_sampled = len(cell_density)
    if cores_sampled == 0:
        cell_density_n_mean = np.nan
        cell_counts_n_mean = np.nan
        core_areas_n_mean = np.nan
        n_den_stdev.append(np.nan)
        n_den_sterr.append(np.nan)
    else:
        cell_density_n_mean = np.nanmean(cell_density)
        cell_counts_n_mean = np.nanmean(cell_counts)
        core_areas_n_mean = np.nanmean(core_areas)
        n_den_stdev.append(np.nanstd(cell_density))
        n_den_sterr.append(np.nanstd(cell_density) / np.sqrt(len(cell_density)))

    sampling_results = {"Density_n_mean": cell_density_n_mean, "Den_stdev": n_den_stdev, "Den_sterr": n_den_sterr, "Boundary": boundary_type, "Block": block, "Radius": radius, "n_cores": n_cores, "Cores_actually_sampled": cores_sampled, "Counts_n_mean": cell_counts_n_mean, "Areas_n_mean": core_areas_n_mean}

    if cores_sampled > 0:
        sampling_results["Density_top_core"] = max(cell_density)

    return sampling_results


def eta_counter(start_time, total_sampled, total_iterations):
    time_per_iteration = (datetime.datetime.now() - start_time) / len(total_sampled)
    time_to_go = time_per_iteration * (total_iterations - len(total_sampled))
    eta = (datetime.datetime.now() + time_to_go).strftime("%B %d, %Y %H:%M:%S")
    return eta, time_per_iteration


def compute_hpfs(block, object_data, plot_annotations, number_of_tumour_regions, boundary_type, hpf_dimension_microns, microns_per_pixel=0.22715):
    # Convert the cell coordinates to a GeoDataFrame
    geometry = [Point(x, y) for x, y in object_data["Cell Centre"]]
    cell_data_gdf = gpd.GeoDataFrame(object_data, geometry=geometry)
    # Create a spatial index for faster intersection checks
    # cell_data_sindex = cell_data_gdf.sindex
    # Assemble annotations
    tumour_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"].tolist()).buffer(0))
    outer_IM_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"][0:number_of_tumour_regions].tolist()).buffer(500 / microns_per_pixel))
    inner_IM_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"][0:number_of_tumour_regions].tolist()).buffer(-500 / microns_per_pixel))
    negative_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Partition Zone"]["Polygon"].tolist()).buffer(0))
    net_tumour = tumour_polygons.difference(negative_polygons)
    partition = outer_IM_polygons.difference(negative_polygons)
    net_IM = partition.difference(inner_IM_polygons)
    analysis_polygon = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"].tolist()).buffer(1000 / microns_per_pixel))
    analysis_polygon = analysis_polygon.difference(negative_polygons)
    # Compute HPFs and densities
    hpf_dimension_pixels = hpf_dimension_microns / microns_per_pixel
    mm2_per_pixels2 = (microns_per_pixel / 1000) ** 2
    computed_hpfs = []
    if boundary_type == "Tumour":
        start_time = datetime.datetime.now()
        print(f"Computing {block} {boundary_type} HPFs...")
        min_x, min_y, max_x, max_y = net_tumour.bounds
        partition_x = int((max_x - min_x) / hpf_dimension_pixels)
        partition_y = int((max_y - min_y) / hpf_dimension_pixels)
        px, py = np.linspace(min_x, max_x, partition_x), np.linspace(min_y, max_y, partition_y)
        total_iterations = partition_x * partition_y
        total_sampled = 0
        for x in range(len(px) - 1):
            for y in range(len(py) - 1):
                if ((total_sampled / 10) % 200 == 0) & (total_sampled > 0):
                    eta = eta_counter(start_time=start_time, total_sampled=list(range(total_sampled)), total_iterations=total_iterations)[0]
                    print(f"ETA: {eta}.")
                total_sampled += 1
                poly_hpf = shapelyPolygon([[px[x], py[y]], [px[x], py[y + 1]], [px[x + 1], py[y + 1]], [px[x + 1], py[y]]])
                hpf_area = poly_hpf.intersection(net_tumour).area
                if hpf_area / poly_hpf.area >= 0.50:
                    # Find the cells that intersect with poly_hpf
                    intersecting_cells = cell_data_gdf[cell_data_gdf.intersects(poly_hpf.intersection(net_tumour))]
                    # Count the intersecting cells
                    cell_count = len(intersecting_cells)
                    cell_den = cell_count / (hpf_area * mm2_per_pixels2)
                    hpf_area = hpf_area * mm2_per_pixels2
                    computed_hpfs.append({"block": block, "region": boundary_type, "hpf": poly_hpf, "density": cell_den, "cell_count": cell_count, "hpf_area": hpf_area})
    if boundary_type == "IM":
        print(f"Computing {block} {boundary_type} HPFs...")
        min_x, min_y, max_x, max_y = net_IM.bounds
        partition_x = int((max_x - min_x) / hpf_dimension_pixels)
        partition_y = int((max_y - min_y) / hpf_dimension_pixels)
        px, py = np.linspace(min_x, max_x, partition_x), np.linspace(min_y, max_y, partition_y)
        for x in range(len(px) - 1):
            for y in range(len(py) - 1):
                poly_hpf = shapelyPolygon([[px[x], py[y]], [px[x], py[y + 1]], [px[x + 1], py[y + 1]], [px[x + 1], py[y]]])
                hpf_area = poly_hpf.intersection(net_IM).area
                if hpf_area / poly_hpf.area >= 0.50:
                    # Find the cells that intersect with poly_hpf
                    intersecting_cells = cell_data_gdf[cell_data_gdf.intersects(poly_hpf.intersection(net_IM))]
                    # Count the intersecting cells
                    cell_count = len(intersecting_cells)
                    cell_den = cell_count / (hpf_area * mm2_per_pixels2)
                    hpf_area = hpf_area * mm2_per_pixels2
                    computed_hpfs.append({"block": block, "region": boundary_type, "hpf": poly_hpf, "density": cell_den, "cell_count": cell_count, "hpf_area": hpf_area})
    return computed_hpfs


def sample_hpfs(block, plot_annotations, hpf_data, percent_tissue_list, boundary_type, n_iterations, number_of_tumour_regions, microns_per_pixel=0.22715):
    # Combine polygons, add to lists to make iterable for MultiPolygon
    tumour_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"].tolist()).buffer(0))
    outer_IM_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"][0:number_of_tumour_regions].tolist()).buffer(500 / microns_per_pixel))
    inner_IM_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"][0:number_of_tumour_regions].tolist()).buffer(-500 / microns_per_pixel))
    negative_polygons = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Partition Zone"]["Polygon"].tolist()).buffer(0))
    net_tumour = tumour_polygons.difference(negative_polygons)
    partition = outer_IM_polygons.difference(negative_polygons)
    net_IM = partition.difference(inner_IM_polygons)
    analysis_polygon = unary_union(MultiPolygon(plot_annotations[plot_annotations["Layer"] == "Tumour"]["Polygon"].tolist()).buffer(1000 / microns_per_pixel))
    analysis_polygon = analysis_polygon.difference(negative_polygons)
    # Refine dataframe
    hpf_data = hpf_data[(hpf_data["block"] == block) & (hpf_data["region"] == boundary_type)]
    mm2_per_pixels2 = (microns_per_pixel / 1000) ** 2
    sampled_hpfs = []
    if boundary_type == "Tumour":
        # Sample n_iterations per area
        for percent in percent_tissue_list:
            # Determine area of tissue by percent
            x_area = (net_tumour.area * mm2_per_pixels2) * percent / 100
            for iteration in range(n_iterations):
                print(f"Sampling {percent}% of {block} {boundary_type}. On iteration {iteration+1}/{n_iterations}.")
                shuffled_data = hpf_data.sample(frac=1)
                sampled_area = 0
                # Randomly select rows until area meets percentage
                for idx, row in shuffled_data.iterrows():
                    if sampled_area + row['hpf_area'] <= x_area:
                        hpf_cell_count = row["cell_count"]
                        hpf_area = row["hpf_area"]
                        sampled_hpfs.append({"block": block, "region": boundary_type, "percent_sampled": percent, "cell_count": hpf_cell_count, "hpf_area": hpf_area})
                        sampled_area += row['hpf_area']
                    else:
                        break
    if boundary_type == "IM":
        # Sample n_iterations per area
        for percent in percent_tissue_list:
            # Determine area of tissue by percent
            x_area = (net_IM.area * mm2_per_pixels2) * percent / 100
            for iteration in range(n_iterations):
                print(f"Sampling {percent}% of {block} {boundary_type}. On iteration {iteration+1}/{n_iterations}.")
                shuffled_data = hpf_data.sample(frac=1)
                sampled_area = 0
                # Randomly select rows until area meets percentage
                for idx, row in shuffled_data.iterrows():
                    if sampled_area + row['hpf_area'] <= x_area:
                        hpf_cell_count = row["cell_count"]
                        hpf_area = row["hpf_area"]
                        sampled_hpfs.append({"block": block, "region": boundary_type, "percent_sampled": percent, "cell_count": hpf_cell_count, "hpf_area": hpf_area})
                        sampled_area += row['hpf_area']
                    else:
                        break
    return sampled_hpfs


def hpf_density_histograms(hpf_data, boundary_type, upper_x_limit, bins, block="total", microns_per_pixel=0.22715, normalize=False):
    if block == "total":
        plot_data = hpf_data[hpf_data["region"] == boundary_type]["density"]
    else:
        plot_data = hpf_data[(hpf_data["block"] == block) & (hpf_data["region"] == boundary_type)]["density"]
    plt.rcParams["font.family"] = ["Arial"]
    plt.rcParams["font.weight"] = "bold"
    plt.rcParams["axes.labelweight"] = "bold"
    colour = "lightcoral"
    if boundary_type == "IM":
        colour = "lightgreen"
    plt.hist(plot_data, bins=bins, edgecolor="black", color=colour)
    plt.title(f"{block} WS HPF {boundary_type} CD8 Density Distribution")
    if block =="total":
        plt.ylim(0,3000)
        plt.legend(["Tumour", "IM"], frameon=False)
    if normalize == True:
        plt.xlabel("Normalized CD8 Density (Stdev from Mean)")
    else:
        plt.xlabel("Density (cells/mm$^2$)")
    plt.ylabel("Frequency")
    # buffer = (upper_x_limit - lower_x_limit) * 0.05
    # plt.xlim(-buffer, upper_x_limit + buffer)
    # Graphpadify
    plt.gca().spines["top"].set_visible(False)
    plt.gca().spines["right"].set_visible(False)
    plt.gca().spines["left"].set_linewidth(2)
    plt.gca().spines["bottom"].set_linewidth(2)
    plt.gca().tick_params(width=2)
    plt.savefig(f"C:/Users/labuser/Desktop/Simulated WS Sampling/HPF_Distributions/{block}_{boundary_type}_HPF_distribution.png", dpi=300)
    plt.cla()
    plt.clf()
    
    
